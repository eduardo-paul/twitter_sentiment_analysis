This is just me playing around a little bit with twitter sentiment analysis, using a dataset collected from https://www.kaggle.com/kazanova/sentiment140. The training data set consists of 1600000 tweets. Each tweet sentiment was classified based on the presence of relevant emoticons. For example, the presence of a ":-)" emoticon would classify the tweet as having a positive sentiment, whereas a ":-(" emoticon would classify it as negative. The first step in the preprocessing phase was to strip the tweets of such emoticons, so they would not bias the training.

Disregarding the neutral tweets present in the test set, the best achieved accuracy score was ~84.69%, by using a basic tokenization followed by a tf-idf transformation, and a linear support-vector classifier with the cost paratmeter C = 0.29. No amount of fancier preprocessing was able to improve the results.
